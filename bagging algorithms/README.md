# Ensemble Learning Projects (Bagging & Boosting) ğŸŒ²ğŸ“ˆ

This repository contains my Machine Learning projects focused on **ensemble algorithms**, specifically **AdaBoost, Random Forest, and XGBoost**, applied to real-world datasets.  
Each project includes complete **data preprocessing, model training, and evaluation**.

---

## ğŸ“Œ Projects Included

---

## 1. Pollution Classification using AdaBoost ğŸŒ

- Built a pollution level classification model using **AdaBoost (Adaptive Boosting)**
- Performed full preprocessing including handling missing values and feature scaling
- Improved predictive performance by combining multiple weak learners

**Algorithm Used:**  
- AdaBoost Classifier  

**Task Type:** Classification  

---

## 2. Pollution Classification using Random Forest ğŸŒ²

- Implemented a robust ensemble model using **Random Forest**
- Conducted preprocessing steps such as encoding, cleaning, and normalization
- Achieved stable classification results through bagging and decision tree aggregation

**Algorithm Used:**  
- Random Forest Classifier  

**Task Type:** Classification  

---

## 3. Sleep Hours Prediction using XGBoost ğŸ˜´

- Developed a prediction model using **XGBoost (Extreme Gradient Boosting)**
- Applied preprocessing including feature engineering and data transformation
- Leveraged gradient boosting for high-performance regression prediction

**Algorithm Used:**  
- XGBoost Regressor  

**Task Type:** Regression  

---

## âœ… Common Workflow Across Projects

Each project follows a complete ML pipeline:

- Data Cleaning and Preprocessing  
- Feature Selection / Transformation  
- Model Training with Ensemble Algorithms  
- Performance Evaluation using appropriate metrics  

---

## ğŸ›  Libraries and Tools Used

- Python  
- Scikit-learn  
- XGBoost  
- Pandas, NumPy  
- Matplotlib  

---

## ğŸ”— Author

Arkajeet  
Mechanical Engineering Undergraduate | Machine Learning Enthusiast  

---

